# üß† AutoDocumentationWithCrewAI

Documenta√ß√£o autom√°tica de c√≥digo utilizando a framework [CrewAI](https://github.com/joaomdmoura/crewAI).

Este projeto organiza agentes colaborativos para analisar e documentar c√≥digo Python de forma aut√¥noma, utilizando ferramentas como leitura de arquivos, an√°lise sem√¢ntica e gera√ß√£o de texto.

---

## üöÄ Funcionalidades

- üìÑ Leitura de arquivos fonte (ex: `.py`)
- üß† An√°lise da estrutura do c√≥digo
- ‚úçÔ∏è Gera√ß√£o autom√°tica de documenta√ß√£o
- ü§ñ Execu√ß√£o em cadeia de agentes (Leitor ‚Üí Analista ‚Üí Documentador)
- üîÑ Integra√ß√£o com GitHub via webhook para automa√ß√£o em push ou pull request
- üåê Exposi√ß√£o local com ngrok para receber webhooks externamente

---

## üõ†Ô∏è Requisitos

- Python 3.11+
- [CrewAI](https://github.com/joaomdmoura/crewAI)
- Ambiente virtual recomendado (venv)
- [ngrok](https://ngrok.com/) para expor localmente a API de webhook (opcional, para testes locais)

---

## üß† Modelos de Linguagem

Este projeto utiliza um modelo de linguagem local atrav√©s do [LM Studio](https://lmstudio.ai/). Isso permite processamento e gera√ß√£o de texto de forma offline, garantindo maior controle e privacidade durante a an√°lise e documenta√ß√£o autom√°tica do c√≥digo e evita a necessidade de ter uma API key.

---

## ‚öôÔ∏è Instala√ß√£o e uso

### 1. Crie e ative o ambiente virtual:

```bash
py -3.11 -m venv .venv
.\.venv\Scripts\activate  # Para Windows
# ou
source .venv/bin/activate  # Para Linux/macOS
```

### 2. Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

### 3. Execute a aplica√ß√£o de webhook (Flask)

Este servidor escuta eventos do GitHub para iniciar a gera√ß√£o autom√°tica da documenta√ß√£o quando um push ocorre.

```bash
py webhook_server.py
```

O servidor vai rodar localmente na porta 5000 (http://localhost:5000/webhook).

### 4. Exponha localmente com ngrok (para receber webhooks do GitHub)

Se quiser testar localmente, voc√™ pode usar o ngrok para criar um t√∫nel HTTP:

```bash
ngrok http 5000
```

- Copie a URL p√∫blica gerada pelo ngrok, algo como https://abcd1234.ngrok.io

- Configure essa URL como webhook no reposit√≥rio GitHub, adicionando /webhook no final (ex: https://abcd1234.ngrok.io/webhook)

### 5. Configure o webhook no GitHub

- V√° em **Settings** ‚Üí **Webhooks** no seu reposit√≥rio GitHub
- Clique em **Add webhook**
- Cole a URL do ngrok com `/webhook`
- Escolha o conte√∫do do tipo `application/json`
- Selecione os eventos que quer ouvir, por exemplo, **push**
- Salve o webhook

### 6. O que acontece quando o webhook √© acionado?

Quando um push √© detectado, o webhook envia uma requisi√ß√£o POST para seu servidor Flask. Ele:

- Extrai a URL do reposit√≥rio do payload
- Inicia em background a gera√ß√£o autom√°tica da documenta√ß√£o chamando `main.py` com par√¢metros
- Retorna uma resposta de confirma√ß√£o

### Como rodar o projeto manualmente

Se quiser rodar sem webhook, pode executar diretamente o script principal:

```bash
py main.py
```

Ao usar essa op√ß√£o, voc√™ poder√° escolher entre **duas formas de execu√ß√£o**:

1. **Usar o link *raw* de um arquivo no GitHub**  
   Basta fornecer a URL direta (*raw*) de um arquivo hospedado no GitHub.  
   O sistema ir√° processar o conte√∫do desse arquivo e gerar a documenta√ß√£o t√©cnica para ele.

2. **Clonar um reposit√≥rio completo**  
   Basta passar o link principal do reposit√≥rio no GitHub, por exemplo:  
   `https://github.com/usuario/repositorio`  
   Em seguida, indicar a *branch* que deseja utilizar.  
   O sistema ir√° clonar essa branch, processar todos os arquivos e gerar a documenta√ß√£o t√©cnica do projeto completo.

## üìÅ Estrutura do projeto

- `main.py` ‚Äî Script principal para gera√ß√£o da documenta√ß√£o.
- `webhook_server.py` ‚Äî Servidor Flask para receber eventos do GitHub.
- `src/custom_tools/` ‚Äî Ferramentas personalizadas para clonagem, download e leitura de c√≥digo.
- `src/config/` ‚Äî Arquivos YAML com configura√ß√µes dos agentes e tarefas.


 ## ‚ùó Limita√ß√µes conhecidas

Como este projeto utiliza um modelo de linguagem local via LM Studio, o que implica depender muito do hardware da m√°quina,algumas limita√ß√µes foram observadas durante o uso:

- üîÅ **Comportamento inst√°vel:** √Äs vezes os agentes funcionam corretamente, outras vezes n√£o. H√° bastante oscila√ß√£o na performance.

- üìÑ **Documenta√ß√£o incorreta ou inventada:** O modelo pode gerar documenta√ß√£o para ficheiros que n√£o existem ou ignorar o output real das tools, acrescentando itens fict√≠cios.

- üß† **Alucina√ß√µes frequentes:** Devido √† complexidade l√≥gica e ao n√∫mero de agentes, o modelo tende a alucinar com frequ√™ncia, especialmente quando o n√∫mero de tokens fica pr√≥ximo do limite.

- ‚ùå **N√£o segue corretamente as instru√ß√µes das tools:** Por exemplo, mesmo quando um ficheiro `.txt` indica quais ficheiros devem ser documentados, o modelo ignora e inventa outros.

- ‚úçÔ∏è **Falta de documenta√ß√£o inline:** Mesmo com tentativas de for√ßar documenta√ß√£o inline nos m√©todos/fun√ß√µes, os resultados s√£o inconsistentes ou inexistentes.

- üí• **Crashes inesperados:** Modelos maiores tendem a gerar mais falhas de execu√ß√£o locais, principalmente por gest√£o de mem√≥ria ou limite de contexto.

 
 
